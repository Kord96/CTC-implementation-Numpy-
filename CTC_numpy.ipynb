{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CTC numpy",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cQ9SKGevt90b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(precision=3,suppress=True, linewidth=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_alphabet = ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','x','w','y','z']\n",
        "class CTC:\n",
        "  #y is in the shape (len(alphabet),T)\n",
        "  def __init__(self,y,label,alphabet = english_alphabet):    \n",
        "    self.label = label\n",
        "    self.y = y\n",
        "    self.init()\n",
        "  def init(self):\n",
        "    self.T = self.y.shape[0]\n",
        "    self.K = self.y.shape[1]\n",
        "    self.S = len(self.label)*2 + 1\n",
        "    self.y = np.insert(self.y,0,0,axis=1)\n",
        "    self.y = np.insert(self.y,0,0,axis=0)\n",
        "    self.letter_to_index = dict(zip(alphabet,range(1,len(alphabet)+1)))\n",
        "    self.index_to_letter = dict(zip(range(1,len(alphabet)+1),alphabet))\n",
        "    self.expanded_label = self.expand_label(self.label)\n",
        "    self.label.insert(0,\"0\")\n",
        "    self.alpha = self.compute_alpha()\n",
        "    self.beta = self.compute_beta()\n",
        "    self.grads = self.compute_grads()\n",
        "    self.loss = self.compute_loss()\n",
        "\n",
        "  def expand_label(self,label):\n",
        "    expanded_label = [' ']\n",
        "    for element in label:\n",
        "      if(element != ' '):\n",
        "        expanded_label.append(element)\n",
        "        expanded_label.append(' ')\n",
        "    expanded_label.insert(0,\"0\")\n",
        "    return expanded_label\n",
        "    \n",
        "  def compute_alpha(self):\n",
        "    \n",
        "    alpha = np.zeros((self.T + 2, self.S + 2))\n",
        "    b = self.letter_to_index[' ']\n",
        "    l1 = self.letter_to_index[self.label[1]]\n",
        "    alpha[1][1] = self.y[1][b]\n",
        "    alpha[1][2] = self.y[1][l1]\n",
        "    \n",
        "    for t in range(2,self.T + 1):\n",
        "      for s in range(1, self.S + 1):\n",
        "        if(s < (self.S - 2*(self.T-t) - 1)):\n",
        "          continue\n",
        "\n",
        "        #_s,_t just to make indexing look similar to the original equation..\n",
        "        _alpha = alpha[t-1][s] + (alpha[t-1][s-1] if s-1 >= 0 else 0 )\n",
        "         \n",
        "        ls = self.letter_to_index[self.expanded_label[s]]\n",
        "        if(self.expanded_label[s] == ' ' or (s >= 2 and self.expanded_label[s-2] == self.expanded_label[s])):\n",
        "          alpha[t][s] = _alpha * self.y[t][ls]\n",
        "\n",
        "        else:\n",
        "          alpha[t][s] = (_alpha + (alpha[t-1][s-2] if s - 2 >= 0 else 0 )) * self.y[t][ls]\n",
        "\n",
        "        \n",
        "    \n",
        "\n",
        "    return alpha\n",
        "\n",
        "  def compute_beta(self):\n",
        "  \n",
        "    beta = np.zeros((self.T + 2,self.S+2))\n",
        "    b = self.letter_to_index[' ']\n",
        "    l_last = self.letter_to_index[self.label[-1]]\n",
        "    beta[self.T][self.S] = self.y[self.T][b]\n",
        "    beta[self.T][self.S-1] = self.y[self.T][l_last]\n",
        "\n",
        "    for s in range(self.S, 0,-1):\n",
        "      for t in range(self.T-1 ,0,-1):\n",
        "        if(s > 2*t):\n",
        "          continue\n",
        "        #_s,_t just to make indexing look similar to the original equation..\n",
        "        _beta = beta[t+1][s] + beta[t+1][s+1]\n",
        "        ls = self.letter_to_index[self.expanded_label[s]]\n",
        "\n",
        "        if(self.expanded_label[s] == ' ' or (s+2 < self.S and self.expanded_label[s+2] == self.expanded_label[s])):\n",
        "          beta[t][s] = _beta * self.y[t][ls]\n",
        "        else:\n",
        "          beta[t][s] = (_beta + beta[t+1][s+2]) * self.y[t][ls]\n",
        "\n",
        "    return beta\n",
        "\n",
        "\n",
        "  def compute_loss(self):\n",
        "    #eq 14\n",
        "    loss = np.zeros(self.S - 1)\n",
        "    prod = self.alpha * self.beta\n",
        "    for s in range(1,self.S+1):\n",
        "      ls = self.letter_to_index[self.expanded_label[s]]\n",
        "      loss += prod[1:self.T + 1,s]*self.y[1:self.T + 1,ls]\n",
        "    \n",
        "    return np.log(sum(loss))\n",
        "\n",
        "  def error_signal(self):\n",
        "\n",
        "    T = self.y.shape[0]\n",
        "    C = np.sum(self.alpha,axis=1)\n",
        "    #this should be vectorized for speed.\n",
        "    alpha_hat = np.array([self.alpha[t]/C[t] for t in range(T)])\n",
        "    D = np.sum(self.beta,axis=1)\n",
        "    beta_hat = np.array([self.beta[t]/D[t] for t in range(T)])\n",
        "\n",
        "    Q = D * np.prod(D/C)\n",
        "    error = np.zeros(self.y.shape)\n",
        "    #I think here we better loop over y time steps?\n",
        "    for element in [' '] + self.label:\n",
        "      ls = self.letter_to_index[element]\n",
        "      grads[:,ls] = self.y[:,ls] - Q/self.y[:,ls] * np.sum(alpha_hat*beta_hat,axis=1)\n",
        "    \n",
        "    return error\n",
        "\n",
        "  def compute_grads(self):\n",
        "    p_lx = self.alpha[self.T,self.S] + self.alpha[self.T,self.S-1]\n",
        "    grads = np.zeros(self.y.shape)\n",
        "    \n",
        "    \n",
        "    #for all the possible chars in output, if the char is in the label return one, otherwise return 0\n",
        "    \n",
        "    #This part needs to be vectorized.\n",
        "    for t in range(1,self.T + 1):\n",
        "      for k in range(1,self.K + 1):\n",
        "        s_sum = 0\n",
        "        lab = np.nonzero(list(map(lambda x: 1 if self.index_to_letter[k] in x else 0, self.expanded_label)))[0]\n",
        "        \n",
        "        for s in lab:\n",
        "            s_sum += self.alpha[t,s] * self.beta[t,s]\n",
        "        \n",
        "        grads[t,k] = (1/p_lx)*(1/(self.y[t,k]**2)) * s_sum\n",
        "    \n",
        "    return grads\n",
        "\n",
        "  def get_alpha(self):\n",
        "    return self.alpha[1:self.T+1,1:self.S+1]\n",
        "\n",
        "  def get_beta(self):\n",
        "    return self.beta[1:self.T+1,1:self.S+1]\n",
        "\n",
        "  def get_y(self):\n",
        "    return self.y[1:,1:]\n",
        "\n",
        "  def get_grads(self):\n",
        "    return self.grads[1:,1:]\n",
        "\n",
        "  def get_loss(self):\n",
        "    return self.loss\n"
      ],
      "metadata": {
        "id": "otAfyZBBuCQf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array([[0.173, 0.892, 0.046, 0.966, 0.601, 0.588],\n",
        " [0.722, 0.358, 0.922, 0.926, 0.69 , 0.488],\n",
        " [0.306 ,0.117, 0.635, 0.872 ,0.167 ,0.053],\n",
        " [0.445, 0.387, 0.165, 0.525 ,0.445, 0.081],\n",
        " [0.585, 0.398, 0.332 ,0.425, 0.415 ,0.511]]).T\n",
        "label = ['b','a','b']\n",
        "alphabet = ['a','b','c','d',' ']\n",
        "\n",
        "tmp = CTC(y,label,alphabet)"
      ],
      "metadata": {
        "id": "3__5jJPRuMoi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = tmp.get_y()\n",
        "print(\"y: {}\\n{}\\n\".format(y.shape,y))\n",
        "\n",
        "alpha = tmp.get_alpha()\n",
        "print(\"alpha: {}\\n{}\\n\".format(alpha.shape,alpha))\n",
        "\n",
        "beta = tmp.get_beta()\n",
        "print(\"beta: {}\\n{}\\n\".format(beta.shape,beta))\n",
        "\n",
        "grads = tmp.get_grads()\n",
        "print(\"grads: {}\\n{}\\n\".format(grads.shape,grads))\n",
        "\n",
        "loss = tmp.get_loss()\n",
        "print(\"loss: {}\\n\".format(loss))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tH1pNhyuPUY",
        "outputId": "c3de27ca-e434-4ed5-bd99-b016b0388af8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y: (6, 5)\n",
            "[[0.173 0.722 0.306 0.445 0.585]\n",
            " [0.892 0.358 0.117 0.387 0.398]\n",
            " [0.046 0.922 0.635 0.165 0.332]\n",
            " [0.966 0.926 0.872 0.525 0.425]\n",
            " [0.601 0.69  0.167 0.445 0.415]\n",
            " [0.588 0.488 0.053 0.081 0.511]]\n",
            "\n",
            "alpha: (6, 7)\n",
            "[[0.585 0.722 0.    0.    0.    0.    0.   ]\n",
            " [0.233 0.468 0.287 0.644 0.    0.    0.   ]\n",
            " [0.077 0.646 0.251 0.064 0.214 0.594 0.   ]\n",
            " [0.    0.67  0.381 0.929 0.118 0.807 0.252]\n",
            " [0.    0.    0.    1.19  0.434 1.279 0.44 ]\n",
            " [0.    0.    0.    0.    0.    1.417 0.879]]\n",
            "\n",
            "beta: (6, 7)\n",
            "[[0.76  1.535 0.    0.    0.    0.    0.   ]\n",
            " [0.601 0.698 0.211 1.217 0.    0.    0.   ]\n",
            " [0.09  1.421 0.421 0.108 0.403 0.853 0.   ]\n",
            " [0.    0.272 0.125 1.145 0.379 0.835 0.09 ]\n",
            " [0.    0.    0.    0.293 0.203 0.689 0.212]\n",
            " [0.    0.    0.    0.    0.    0.488 0.511]]\n",
            "\n",
            "grads: (6, 5)\n",
            "[[0.    0.926 0.    0.    0.566]\n",
            " [0.429 1.111 0.    0.    0.552]\n",
            " [1.438 0.73  0.    0.    0.786]\n",
            " [0.496 0.435 0.    0.    0.278]\n",
            " [0.421 0.807 0.    0.    0.458]\n",
            " [0.    1.265 0.    0.    0.749]]\n",
            "\n",
            "loss: 1.8967660063709553\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4sIu-e_PuRqb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}